import numpy as np
import re


# normalize function
def normalize_text(text):
    # link
    text = re.sub(r"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\(\), ]|(?:%[0-9a-fA-F][0-9a-fA-F]))+", ' <link> ', text, flags=re.MULTILINE)

    # email
    text = re.sub(r"[\w\.-]+@[\w\.-]+", ' <email> ', text, flags=re.MULTILINE)

    # image
    text = re.sub(r"(\w)*\.(?:jpg|gif|png)", ' <image> ', text, flags=re.MULTILINE)

    # atm
    text = re.sub(r"\b\d{12,16}\b", ' <atm> ', text, flags=re.MULTILINE)

    # phone
    text = re.sub(r"\b\d{10,11}\b", ' <telephone> ', text, flags=re.MULTILINE)

    # price
    text = re.sub(r"\d+(k|l|K|L|\$|USD)", ' <money> ', text, flags=re.MULTILINE)

    # measure
    text = re.sub(r"\d+(cm|m|km|mm|g|kg)", ' <measure> ', text, flags=re.MULTILINE)

    # unusual
    text = re.sub(r"(/|\|\n\n|\n)", ' ', text, flags=re.MULTILINE)

    # emoji
    text = re.sub(
        u"([\U00002600-\U000027BF])|([\U0001f300-\U0001f64F])|([\U0001f680-\U0001f6FF])|([\U00010000-\U0010ffff])",
        ' <emoji> ', text, flags=re.MULTILINE)

    # Remove c√°c k√Ω t·ª± k√©o d√†i: vd: ƒë·∫πppppppp
    text = re.sub(r'([A-Z])\1+', lambda m: m.group(1).upper(), text, flags=re.IGNORECASE)

    # Chuy·ªÉn th√†nh ch·ªØ th∆∞·ªùng
    text = text.lower()

    replace_list = {
        '√≤a': 'o√†', '√≥a': 'o√°', '·ªèa': 'o·∫£', '√µa': 'o√£', '·ªça': 'o·∫°', '√≤e': 'o√®', '√≥e': 'o√©', '·ªèe': 'o·∫ª',
        '√µe': 'o·∫Ω', '·ªçe': 'o·∫π', '√πy': 'u·ª≥', '√∫y': 'u√Ω', '·ªßy': 'u·ª∑', '≈©y': 'u·ªπ', '·ª•y': 'u·ªµ', 'u·∫£': '·ªßa',
        'aÃâ': '·∫£', '√¥ÃÅ': '·ªë', 'u¬¥': '·ªë', '√¥ÃÉ': '·ªó', '√¥ÃÄ': '·ªì', '√¥Ãâ': '·ªï', '√¢ÃÅ': '·∫•', '√¢ÃÉ': '·∫´', '√¢Ãâ': '·∫©',
        '√¢ÃÄ': '·∫ß', 'oÃâ': '·ªè', '√™ÃÄ': '·ªÅ', '√™ÃÉ': '·ªÖ', 'ƒÉÃÅ': '·∫Ø', 'uÃâ': '·ªß', '√™ÃÅ': '·∫ø', '∆°Ãâ': '·ªü', 'iÃâ': '·ªâ',
        'eÃâ': '·∫ª', '√†k': u' √† ', 'aÀã': '√†', 'iÀã': '√¨', 'ƒÉ¬¥': '·∫Ø', '∆∞Ãâ': '·ª≠', 'eÀú': '·∫Ω', 'yÀú': '·ªπ', 'a¬¥': '√°',

        # Chu·∫©n h√≥a 1 s·ªë sentiment words/English words
        '√¥ k√™i': ' ok ', 'okie': ' ok ', ' o k√™ ': ' ok ',
        'okey': ' ok ', '√¥k√™': ' ok ', 'oki': ' ok ', ' oke ': ' ok ', ' okay': ' ok ', 'ok√™': ' ok ',
        ' tks ': u' c√°m ∆°n ', 'thks': u' c√°m ∆°n ', 'thanks': u' c√°m ∆°n ', 'ths': u' c√°m ∆°n ', 'thank': u' c√°m ∆°n ',
        '‚≠ê': 'star ', '*': 'star ', 'üåü': 'star ', u'\n': ' ', u')': ' ', u'(': ' ',
        'kg ': u' kh√¥ng ', 'not': u' kh√¥ng ', u' kg ': u' kh√¥ng ', '"k ': u' kh√¥ng ', ' kh ': u' kh√¥ng ',
        'k√¥': u' kh√¥ng ', 'hok': u' kh√¥ng ', ' kp ': u' kh√¥ng ph·∫£i ', u' k√¥ ': u' kh√¥ng ', '"ko ': u' kh√¥ng ',
        u' ko ': u' kh√¥ng ', u' k ': u' kh√¥ng ', 'khong': u' kh√¥ng ', u' hok ': u' kh√¥ng ',
        ' vs ': u' v·ªõi ', 'wa': ' qu√° ', 'w√°': u' qu√°', 'j': u' g√¨ ', '‚Äú': ' ',
        ' sz ': u' c·ª° ', 'size': u' c·ª° ', u' ƒëx ': u' ƒë∆∞·ª£c ', 'dk': u' ƒë∆∞·ª£c ', 'dc': u' ƒë∆∞·ª£c ', 'ƒëk': u' ƒë∆∞·ª£c ',
        'ƒëc': u' ƒë∆∞·ª£c ', 'authentic': u' chu·∫©n ch√≠nh h√£ng ', u' aut ': u' chu·∫©n ch√≠nh h√£ng ',
        u' auth ': u' chu·∫©n ch√≠nh h√£ng ', 'thick': u' positive ', 'store': u' c·ª≠a h√†ng ',
        'shop': u' c·ª≠a h√†ng ', 'sp': u' s·∫£n ph·∫©m ', 'gud': u' t·ªët ', 'god': u' t·ªët ', 'wel done': ' t·ªët ',
        'good': u' t·ªët ', 'g√∫t': u' t·ªët ',
        's·∫•u': u' x·∫•u ', 'gut': u' t·ªët ', u' tot ': u' t·ªët ', u' nice ': u' t·ªët ', 'perfect': 'r·∫•t t·ªët',
        'bt': u' b√¨nh th∆∞·ªùng ',
        'time': u' th·ªùi gian ', 'q√°': u' qu√° ', u' ship ': u' giao h√†ng ', u' m ': u' m√¨nh ', u' mik ': u' m√¨nh ',
        '√™Ãâ': '·ªÉ', 'product': 's·∫£n ph·∫©m', 'quality': 'ch·∫•t l∆∞·ª£ng', 'chat': ' ch·∫•t ', 'excelent': 'ho√†n h·∫£o',
        'bad': 't·ªá', 'fresh': ' t∆∞∆°i ', 'sad': ' t·ªá ',
        'date': u' h·∫°n s·ª≠ d·ª•ng ', 'hsd': u' h·∫°n s·ª≠ d·ª•ng ', 'quickly': u' nhanh ', 'quick': u' nhanh ',
        'fast': u' nhanh ', 'delivery': u' giao h√†ng ', u' s√≠p ': u' giao h√†ng ',
        'beautiful': u' ƒë·∫πp tuy·ªát v·ªùi ', u' r ': u' r·ªìi ', u' shopE ': u' c·ª≠a h√†ng ', u' order ': u' ƒë·∫∑t h√†ng ',
        'ch·∫•t lg': u' ch·∫•t l∆∞·ª£ng ', u' sd ': u' s·ª≠ d·ª•ng ', u' dt ': u' ƒëi·ªán tho·∫°i ', u' nt ': u' nh·∫Øn tin ',
        u' tl ': u' tr·∫£ l·ªùi ', u' s√†i ': u' x√†i ', u'bjo': u' bao gi·ªù ',
        'thik': u' th√≠ch ', u' sop ': u' c·ª≠a h√†ng ', ' fb ': ' facebook ', ' face ': ' facebook ', ' very ': u' r·∫•t ',
        u'qu·∫£ ng ': u' qu·∫£ng  ',
        'dep': u' ƒë·∫πp ', u' xau ': u' x·∫•u ', 'delicious': u' ngon ', u'h√†g': u' h√†ng ', u'q·ªßa': u' qu·∫£ ',
        'iu': u' y√™u ', 'fake': u' gi·∫£ m·∫°o ', 'trl': 'tr·∫£ l·ªùi', '><': u' positive ',
        ' por ': u' t·ªá ', ' poor ': u' t·ªá ', 'ib': u' nh·∫Øn tin ', 'rep': u' tr·∫£ l·ªùi ', u'fback': ' feedback ',
        'fedback': ' feedback ',

        # c√°c t·ª´ nghi v·∫•n
        'nh·ªâ': ' <endturn> ', '?': ' <endturn> ', 'th·∫ø n√†o': ' <endturn> ', 'c√≤n kh√¥ng': ' <endturn> ',
        'c√≥ kh√¥ng': ' <endturn> ', 'c√≤n ko': ' <endturn> ', 'c√≥ ko': ' <endturn> ',
    }

    for k, v in replace_list.items():
        text = text.replace(k, v)

#     # chuyen punctuation th√†nh space
#     translator = str.maketrans(string.punctuation, ' ' * len(string.punctuation))
#     text = text.translate(translator)

    # remove n·ªët nh·ªØng k√Ω t·ª± th·ª´a th√£i
    text = text.replace(u'"', u' ')
    text = text.replace(u'Ô∏è', u'')
    text = text.replace('üèª', '')
    text = text.strip()
    return text

# Function to calculate the accuracy of our predictions vs labels
def flat_accuracy(preds, labels):
    pred_flat = np.argmax(preds, axis=1).flatten()
    labels_flat = labels.flatten()
    return np.sum(pred_flat == labels_flat) / len(labels_flat)